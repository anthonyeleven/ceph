# -*- mode: YAML -*-
---

options:
- name: mgr_data
  type: str
  level: advanced
  desc: Filesystem path to the Manager's data directory, which contains keyrings
    and other data
  default: /var/lib/ceph/mgr/$cluster-$id
  services:
  - mgr
  flags:
  - no_mon_update
- name: mgr_pool
  type: bool
  level: dev
  desc: Allow use/creation of the ``.mgr`` pool. Hey, hacker, leave this value alone.
  default: true
  services:
  - mgr
  flags:
  - startup
- name: mgr_stats_period
  type: int
  level: basic
  desc: Period in seconds of OSD/MDS stats reports to the Manager
  long_desc: Use this setting to control the granularity of time series data collection
    from daemons.  Adjust upwards if the Manager daemon's CPU load is too high, or if you
    do not require the most up to date performance counter data.
  default: 5
  services:
  - mgr
  - common
- name: mgr_client_bytes
  type: size
  level: dev
  default: 128_M
  services:
  - mgr
- name: mgr_client_messages
  type: uint
  level: dev
  default: 512
  services:
  - mgr
- name: mgr_osd_bytes
  type: size
  level: dev
  default: 512_M
  services:
  - mgr
- name: mgr_osd_messages
  type: uint
  level: dev
  default: 8_K
  services:
  - mgr
- name: mgr_mds_bytes
  type: size
  level: dev
  default: 128_M
  services:
  - mgr
- name: mgr_mds_messages
  type: uint
  level: dev
  default: 128
  services:
  - mgr
- name: mgr_mon_bytes
  type: size
  level: dev
  default: 128_M
  services:
  - mgr
- name: mgr_mon_messages
  type: uint
  level: dev
  default: 128
  services:
  - mgr
- name: mgr_service_beacon_grace
  type: float
  level: advanced
  desc: Period in seconds from the last beacon received by the Mmanager after which the
    state of monitored services (RGW, rbd-mirror etc) are dropped
  default: 1_min
  services:
  - mgr
- name: mgr_debug_aggressive_pg_num_changes
  type: bool
  level: dev
  desc: Bypass most throttling and safety checks in the Manager's ``pg_num`` and ``pgp_num`` logic
  default: false
  services:
  - mgr
- name: mgr_max_pg_num_change
  type: int
  level: advanced
  desc: Maximum ``pg_num`` step
  default: 128
  services:
  - mgr
  with_legacy: true
- name: mgr_max_pg_creating
  type: uint
  level: advanced
  desc: Max number of placement groups to create at once
  default: 1024
  services:
  - mgr
- name: mgr_module_path
  type: str
  level: advanced
  desc: Filesystem path to Manager modules.
  default: @CEPH_INSTALL_DATADIR@/mgr
  services:
  - mgr
- name: mgr_standby_modules
  type: bool
  default: true
  level: advanced
  desc: Start modules in standby (redirect) mode when a Manager is standby
  long_desc: By default, modules managed by a standby Manager will answer incoming requests with a
    HTTP redirect to the active Manager.  This allowing users to point their browser at any
    Manager and find their way to the active Manager.  However, this mode is problematic
    when using a load balancer because (1) the redirect targets are usually private
    IP addressess and (2) the load balancer can't identify which Manager to which to send
    traffic. If a load balancer is being used, set this to false.
- name: mgr_disabled_modules
  type: str
  level: advanced
  desc: List of manager modules never get loaded
  long_desc: A comma-delimited list of module names. This list is read by the Manager
    when it starts. By default the Manager loads all modules in the ``mgr_module_path``,
    and starts the enabled modules. The modules in this list will not
    be loaded.
  default: @mgr_disabled_modules@
  services:
  - mgr
  see_also:
  - mgr_module_path
  flags:
  - startup
- name: mgr_initial_modules
  type: str
  level: basic
  desc: List of Manager modules to enable when the cluster is first started
  long_desc: This list of module names is read by the monitor when the cluster is
    first started after installation in order to populate the list of enabled modules.  Subsequent
    updates are done using ``mgr module [enable|disable]`` commands.  The list may be
    comma or space separated.
  default: iostat nfs
  services:
  - mon
  - common
  flags:
  - no_mon_update
  - cluster_create
- name: cephadm_path
  type: str
  level: advanced
  desc: Path to the ``cephadm`` utility
  default: /usr/sbin/cephadm
  services:
  - mgr
- name: mon_delta_reset_interval
  type: float
  level: advanced
  desc: Window for rate calculations reported by ``ceph status``
  fmt_desc: Seconds of inactivity before we reset the PG delta to 0.
    Ceph tracks the delta of the used space of each pool, so, for
    example, it would be easier for us to understand the progress of
    recovery or the performance of a legacy cache tier. If there's no
    activity reported for a certain pool, we reset the history of
    deltas for that pool.
  default: 10
  services:
  - mgr
  with_legacy: true
- name: mon_stat_smooth_intervals
  type: uint
  level: advanced
  desc: Number of PGMaps stats over which we calc the average read/write throughput
    of the whole cluster
  fmt_desc: Ceph will smooth statistics over the last ``N`` PG maps.
  default: 6
  services:
  - mgr
  min: 1
- name: mon_pool_quota_warn_threshold
  type: int
  level: advanced
  desc: Percent of pool quota above which to issue warnings
  default: 0
  services:
  - mgr
- name: mon_pool_quota_crit_threshold
  type: int
  level: advanced
  desc: Percent of pool quota above which to issue errors
  default: 0
  services:
  - mgr
- name: mon_cache_target_full_warn_ratio
  type: float
  level: advanced
  desc: Raise the ``CACHE_POOL_NEAR_FULL`` health warning when cache pool utilization exceeds
    this fraction of total capacity
  long_desc: Raise the ``CACHE_POOL_NEAR_FULL`` health warning when cache pool utilization exceeds
    this fraction of total capacity.  Note that cache tiers / pools are deprecated and will
    be removed by a future release.  New deployments are strongly discouraged and existing
    deployments are advised to remove cache tiering.
  fmt_desc: The value must be between the pool's ``cache_target_full`` and ``target_max_object``
  default: 0.66
  services:
  - mgr
  flags:
  - no_mon_update
  - cluster_create
  with_legacy: true
- name: mon_pg_check_down_all_threshold
  type: float
  level: advanced
  desc: Percentage of ``down`` OSDs above which we check all placement groups for staleness
  fmt_desc: Percentage of ``down`` OSDs above which we check all placement groups for staleness
  default: 0.5
  services:
  - mgr
  with_legacy: true
- name: mon_pg_stuck_threshold
  type: int
  level: advanced
  desc: Number of seconds after which placement groups can be considered stuck ``inactive``, ``unclean``, etc
  long_desc: See doc/control.rst under ``dump_stuck`` for more info
  fmt_desc: Number of seconds after which placement groups with unusual states can be considered stuck.
  default: 1_min
  services:
  - mgr
- name: mon_pg_warn_min_per_osd
  type: uint
  level: advanced
  desc: Minimal number of placement groups per ``in`` OSD below which we raise a health warning
  fmt_desc: Raise ``HEALTH_WARN`` if the average number
    of placement groups per ``in`` OSD is less than this number. A non-positive value
    disables raising the health warning.
  default: 0
  services:
  - mgr
- name: mon_pg_warn_max_object_skew
  type: float
  level: advanced
  desc: Skew among average RADOS objects per PG above which to warn
  fmt_desc: Raise ``HEALTH_WARN`` if the average RADOS object count per
    placement group
    of any pool is greater than ``mon_pg_warn_max_object_skew`` times
    the average RADOS object count per PG of all pools. A non-positive value
    number disables this. Note that this option applies to Manager daemons
    despite the name.
  default: 10
  services:
  - mgr
- name: mon_pg_warn_min_objects
  type: int
  level: advanced
  desc: Do not warn if the total number of RADOS objects in cluster is below
    this number
  default: 10000
  services:
  - mgr
- name: mon_pg_warn_min_pool_objects
  type: int
  level: advanced
  desc: Do not warn on pools whose RADOS object count is below this number
  default: 1000
  services:
  - mgr
- name: mon_warn_on_misplaced
  type: bool
  level: advanced
  desc: Issue a health warning if there are misplaced objects
  long_desc: Older Ceph releases raised a health warning for backfilling or
    misplaced RADOS objects.  Increasingly large clusters, especially when
    the balancer is active, will frequently manifest backfilling or misplaced RADOS
    objects, which generally do not represent heightened risk to data
    availability or durability.  Operators in rare circumstances may
    re-enable this behavior for compatibility until legacy tools are updated.
  default: false
  services:
  - mgr
  with_legacy: true
- name: mon_warn_on_pool_no_app
  type: bool
  level: dev
  desc: Raise the ``POOL_APP_NOT_ENABLED`` health warning if a RADOS pool has no application enabled
  long_desc: Each RADOS pool should have an application association:  rgw, rbd, etc.
  default: true
  services:
  - mgr
- name: mon_warn_on_pool_no_app_grace
  type: secs
  level: dev
  desc: Time after which the ``POOL_APP_NOT_ENABLED`` health warning is issued
  long_desc: Each RADOS pool should have an application association:  rgw, rbd, etc.
  default: 5_min
  services:
  - mgr
  see_also:
  - mon_warn_on_pool_no_app
- name: mon_warn_on_too_few_osds
  type: bool
  level: advanced
  desc: Issue a health warning if there are fewer OSDs than ``osd_pool_default_size``
  default: true
  services:
  - mgr
- name: mon_target_pg_per_osd
  type: uint
  level: advanced
  desc: The PG autoscaler targets this many placement groups per OSD
  long_desc: When managing each pool, the PG autoscaler will attempt to
    reach this target.  In some circumstances, it may exceed this target, up to the
    ``mon_max_pg_per_osd`` limit. Conversely, a lower number of PGs per OSD may be
    created if the cluster is not yet fully utilized
  default: 100
  min: 1
# min pgs per osd for reweight-by-pg command
- name: mon_reweight_min_pgs_per_osd
  type: uint
  level: advanced
  desc: Override reweighting is deprecated in favor of pg-upmap balancing for most deployments
  default: 10
  services:
  - mgr
  with_legacy: true
# min bytes per osd for reweight-by-utilization command
- name: mon_reweight_min_bytes_per_osd
  type: size
  level: advanced
  desc: Override reweighting is deprecated in favor of pg-upmap balancing for most deployments
  default: 100_M
  services:
  - mgr
  with_legacy: true
# max osds to change per reweight-by-* command
- name: mon_reweight_max_osds
  type: int
  level: advanced
  desc: Override reweighting is deprecated in favor of pg-upmap balancing for most deployments
  default: 4
  services:
  - mgr
  with_legacy: true
- name: mon_reweight_max_change
  type: float
  level: advanced
  desc: Override reweighting is deprecated in favor of pg-upmap balancing for most deployments
  default: 0.05
  services:
  - mgr
  with_legacy: true
- name: mgr_stats_threshold
  type: int
  level: advanced
  desc: Lowest perfcounter priority collected by the Manager
  long_desc: Daemons only send perf counter data to the Manager daemon if the counter
    has a priority higher than this.
  default: 5
  min: 0
  max: 11
- name: mgr_tick_period
  type: secs
  level: advanced
  desc: Period in seconds between beacon messages to Monitors
  fmt_desc: How many seconds between Manager beacons to Monitors, and other
    periodic checks.
  default: 2
  services:
  - mgr
  - mon
- name: mon_osd_err_op_age_ratio
  type: float
  level: advanced
  desc: raise the ``REQUEST_STUCK`` health error if OSD ops are older than this value in seconds
  default: 128
  services:
  - mgr
  with_legacy: true
